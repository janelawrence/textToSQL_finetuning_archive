sudo: effective uid is not 0, is /usr/bin/sudo on a file system with the 'nosuid' option set or an NFS file system without root privileges?
Downloading builder script:   0%|          | 0.00/3.94k [00:00<?, ?B/s]Downloading builder script: 100%|██████████| 3.94k/3.94k [00:00<00:00, 3.83MB/s]
Downloading metadata:   0%|          | 0.00/1.97k [00:00<?, ?B/s]Downloading metadata: 100%|██████████| 1.97k/1.97k [00:00<00:00, 2.05MB/s]
Downloading readme:   0%|          | 0.00/4.69k [00:00<?, ?B/s]Downloading readme: 100%|██████████| 4.69k/4.69k [00:00<00:00, 3.85MB/s]
Downloading data:   0%|          | 0.00/99.7M [00:00<?, ?B/s]Downloading data:   6%|▋         | 6.24M/99.7M [00:00<00:01, 62.4MB/s]Downloading data:  16%|█▌        | 16.2M/99.7M [00:00<00:00, 84.0MB/s]Downloading data:  25%|██▌       | 25.3M/99.7M [00:00<00:00, 87.3MB/s]Downloading data:  35%|███▌      | 34.9M/99.7M [00:00<00:00, 91.0MB/s]Downloading data:  45%|████▍     | 44.6M/99.7M [00:00<00:00, 93.0MB/s]Downloading data:  54%|█████▍    | 54.0M/99.7M [00:00<00:00, 93.2MB/s]Downloading data:  63%|██████▎   | 63.3M/99.7M [00:00<00:00, 93.2MB/s]Downloading data:  73%|███████▎  | 72.6M/99.7M [00:00<00:00, 93.3MB/s]Downloading data:  82%|████████▏ | 82.0M/99.7M [00:00<00:00, 93.5MB/s]Downloading data:  92%|█████████▏| 91.4M/99.7M [00:01<00:00, 92.6MB/s]Downloading data: 100%|██████████| 99.7M/99.7M [00:01<00:00, 91.3MB/s]
Generating train split:   0%|          | 0/7000 [00:00<?, ? examples/s]Generating train split:   0%|          | 1/7000 [00:00<47:39,  2.45 examples/s]Generating train split:   9%|▉         | 663/7000 [00:00<00:03, 1716.48 examples/s]Generating train split:  18%|█▊        | 1250/7000 [00:00<00:02, 2836.25 examples/s]Generating train split:  27%|██▋       | 1896/7000 [00:00<00:01, 3841.86 examples/s]Generating train split:  36%|███▌      | 2485/7000 [00:00<00:01, 4422.99 examples/s]Generating train split:  44%|████▍     | 3067/7000 [00:00<00:00, 4823.79 examples/s]Generating train split:  52%|█████▏    | 3668/7000 [00:01<00:00, 5168.59 examples/s]Generating train split:  61%|██████    | 4268/7000 [00:01<00:00, 5409.01 examples/s]Generating train split:  70%|██████▉   | 4887/7000 [00:01<00:00, 5637.81 examples/s]Generating train split:  83%|████████▎ | 5779/7000 [00:01<00:00, 5751.90 examples/s]Generating train split:  92%|█████████▏| 6405/7000 [00:01<00:00, 5887.31 examples/s]                                                                                    Generating validation split:   0%|          | 0/1034 [00:00<?, ? examples/s]Generating validation split:  52%|█████▏    | 542/1034 [00:00<00:00, 5402.80 examples/s]                                                                                          0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 793.10it/s]
Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]Downloading spiece.model: 100%|██████████| 792k/792k [00:00<00:00, 28.9MB/s]
Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]Downloading (…)cial_tokens_map.json: 100%|██████████| 2.20k/2.20k [00:00<00:00, 980kB/s]
Downloading (…)okenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]Downloading (…)okenizer_config.json: 100%|██████████| 2.54k/2.54k [00:00<00:00, 1.88MB/s]
Map:   0%|          | 0/6440 [00:00<?, ? examples/s]Map:  16%|█▌        | 1000/6440 [00:02<00:12, 442.05 examples/s]Map:  31%|███       | 2000/6440 [00:04<00:10, 441.16 examples/s]Map:  47%|████▋     | 3000/6440 [00:06<00:07, 442.74 examples/s]Map:  62%|██████▏   | 4000/6440 [00:08<00:05, 448.00 examples/s]Map:  78%|███████▊  | 5000/6440 [00:11<00:03, 445.53 examples/s]Map:  93%|█████████▎| 6000/6440 [00:13<00:00, 444.89 examples/s]Map: 100%|██████████| 6440/6440 [00:14<00:00, 445.94 examples/s]                                                                Map:   0%|          | 0/1034 [00:00<?, ? examples/s]Map:  97%|█████████▋| 1000/1034 [00:01<00:00, 504.68 examples/s]                                                                Downloading (…)lve/main/config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|██████████| 662/662 [00:00<00:00, 573kB/s]
Downloading pytorch_model.bin:   0%|          | 0.00/3.13G [00:00<?, ?B/s]Downloading pytorch_model.bin:   1%|          | 31.5M/3.13G [00:00<00:10, 309MB/s]Downloading pytorch_model.bin:   2%|▏         | 62.9M/3.13G [00:00<00:09, 312MB/s]Downloading pytorch_model.bin:   3%|▎         | 105M/3.13G [00:00<00:09, 318MB/s] Downloading pytorch_model.bin:   5%|▍         | 147M/3.13G [00:00<00:09, 306MB/s]Downloading pytorch_model.bin:   6%|▌         | 189M/3.13G [00:00<00:09, 311MB/s]Downloading pytorch_model.bin:   7%|▋         | 220M/3.13G [00:00<00:09, 310MB/s]Downloading pytorch_model.bin:   8%|▊         | 262M/3.13G [00:00<00:09, 314MB/s]Downloading pytorch_model.bin:  10%|▉         | 304M/3.13G [00:00<00:08, 316MB/s]Downloading pytorch_model.bin:  11%|█         | 346M/3.13G [00:01<00:08, 321MB/s]Downloading pytorch_model.bin:  12%|█▏        | 388M/3.13G [00:01<00:08, 324MB/s]Downloading pytorch_model.bin:  14%|█▎        | 430M/3.13G [00:01<00:08, 315MB/s]Downloading pytorch_model.bin:  15%|█▌        | 472M/3.13G [00:01<00:08, 310MB/s]Downloading pytorch_model.bin:  16%|█▌        | 503M/3.13G [00:01<00:08, 311MB/s]Downloading pytorch_model.bin:  17%|█▋        | 545M/3.13G [00:01<00:08, 313MB/s]Downloading pytorch_model.bin:  18%|█▊        | 577M/3.13G [00:01<00:08, 312MB/s]Downloading pytorch_model.bin:  19%|█▉        | 608M/3.13G [00:01<00:08, 310MB/s]Downloading pytorch_model.bin:  21%|██        | 650M/3.13G [00:02<00:07, 312MB/s]Downloading pytorch_model.bin:  22%|██▏       | 682M/3.13G [00:02<00:07, 310MB/s]Downloading pytorch_model.bin:  23%|██▎       | 713M/3.13G [00:02<00:07, 304MB/s]Downloading pytorch_model.bin:  24%|██▍       | 744M/3.13G [00:02<00:07, 304MB/s]Downloading pytorch_model.bin:  25%|██▍       | 776M/3.13G [00:02<00:07, 306MB/s]Downloading pytorch_model.bin:  26%|██▌       | 807M/3.13G [00:02<00:07, 294MB/s]Downloading pytorch_model.bin:  27%|██▋       | 849M/3.13G [00:02<00:07, 301MB/s]Downloading pytorch_model.bin:  28%|██▊       | 881M/3.13G [00:02<00:07, 304MB/s]Downloading pytorch_model.bin:  29%|██▉       | 923M/3.13G [00:02<00:07, 311MB/s]Downloading pytorch_model.bin:  30%|███       | 954M/3.13G [00:03<00:07, 307MB/s]Downloading pytorch_model.bin:  31%|███▏      | 986M/3.13G [00:03<00:07, 306MB/s]Downloading pytorch_model.bin:  33%|███▎      | 1.03G/3.13G [00:03<00:06, 317MB/s]Downloading pytorch_model.bin:  34%|███▍      | 1.07G/3.13G [00:03<00:06, 315MB/s]Downloading pytorch_model.bin:  35%|███▌      | 1.11G/3.13G [00:03<00:06, 307MB/s]Downloading pytorch_model.bin:  36%|███▋      | 1.14G/3.13G [00:03<00:06, 308MB/s]Downloading pytorch_model.bin:  37%|███▋      | 1.17G/3.13G [00:03<00:06, 309MB/s]Downloading pytorch_model.bin:  39%|███▉      | 1.22G/3.13G [00:03<00:06, 317MB/s]Downloading pytorch_model.bin:  40%|████      | 1.26G/3.13G [00:04<00:05, 321MB/s]Downloading pytorch_model.bin:  42%|████▏     | 1.30G/3.13G [00:04<00:05, 319MB/s]Downloading pytorch_model.bin:  43%|████▎     | 1.34G/3.13G [00:04<00:05, 311MB/s]Downloading pytorch_model.bin:  44%|████▍     | 1.37G/3.13G [00:04<00:05, 310MB/s]Downloading pytorch_model.bin:  45%|████▍     | 1.41G/3.13G [00:04<00:05, 310MB/s]Downloading pytorch_model.bin:  46%|████▌     | 1.44G/3.13G [00:04<00:05, 310MB/s]Downloading pytorch_model.bin:  47%|████▋     | 1.48G/3.13G [00:04<00:05, 312MB/s]Downloading pytorch_model.bin:  48%|████▊     | 1.51G/3.13G [00:04<00:05, 311MB/s]Downloading pytorch_model.bin:  50%|████▉     | 1.55G/3.13G [00:04<00:05, 315MB/s]Downloading pytorch_model.bin:  51%|█████     | 1.59G/3.13G [00:05<00:04, 319MB/s]Downloading pytorch_model.bin:  52%|█████▏    | 1.64G/3.13G [00:05<00:04, 322MB/s]Downloading pytorch_model.bin:  54%|█████▎    | 1.68G/3.13G [00:05<00:04, 326MB/s]Downloading pytorch_model.bin:  55%|█████▍    | 1.72G/3.13G [00:05<00:04, 336MB/s]Downloading pytorch_model.bin:  56%|█████▌    | 1.76G/3.13G [00:05<00:04, 326MB/s]Downloading pytorch_model.bin:  58%|█████▊    | 1.80G/3.13G [00:05<00:04, 326MB/s]Downloading pytorch_model.bin:  59%|█████▉    | 1.85G/3.13G [00:05<00:03, 324MB/s]Downloading pytorch_model.bin:  60%|██████    | 1.89G/3.13G [00:06<00:03, 326MB/s]Downloading pytorch_model.bin:  62%|██████▏   | 1.93G/3.13G [00:06<00:03, 326MB/s]Downloading pytorch_model.bin:  63%|██████▎   | 1.97G/3.13G [00:06<00:03, 324MB/s]Downloading pytorch_model.bin:  64%|██████▍   | 2.01G/3.13G [00:06<00:03, 324MB/s]Downloading pytorch_model.bin:  66%|██████▌   | 2.06G/3.13G [00:06<00:03, 336MB/s]Downloading pytorch_model.bin:  67%|██████▋   | 2.10G/3.13G [00:06<00:03, 336MB/s]Downloading pytorch_model.bin:  68%|██████▊   | 2.14G/3.13G [00:06<00:02, 336MB/s]Downloading pytorch_model.bin:  70%|██████▉   | 2.18G/3.13G [00:06<00:02, 332MB/s]Downloading pytorch_model.bin:  71%|███████   | 2.22G/3.13G [00:07<00:02, 331MB/s]Downloading pytorch_model.bin:  72%|███████▏  | 2.26G/3.13G [00:07<00:02, 326MB/s]Downloading pytorch_model.bin:  74%|███████▎  | 2.31G/3.13G [00:07<00:02, 325MB/s]Downloading pytorch_model.bin:  75%|███████▍  | 2.35G/3.13G [00:07<00:02, 330MB/s]Downloading pytorch_model.bin:  76%|███████▋  | 2.39G/3.13G [00:07<00:02, 331MB/s]Downloading pytorch_model.bin:  78%|███████▊  | 2.43G/3.13G [00:07<00:02, 328MB/s]Downloading pytorch_model.bin:  79%|███████▉  | 2.47G/3.13G [00:07<00:02, 323MB/s]Downloading pytorch_model.bin:  80%|████████  | 2.52G/3.13G [00:07<00:01, 328MB/s]Downloading pytorch_model.bin:  82%|████████▏ | 2.56G/3.13G [00:08<00:01, 334MB/s]Downloading pytorch_model.bin:  83%|████████▎ | 2.60G/3.13G [00:08<00:01, 325MB/s]Downloading pytorch_model.bin:  84%|████████▍ | 2.64G/3.13G [00:08<00:01, 324MB/s]Downloading pytorch_model.bin:  86%|████████▌ | 2.68G/3.13G [00:08<00:01, 321MB/s]Downloading pytorch_model.bin:  87%|████████▋ | 2.73G/3.13G [00:08<00:01, 316MB/s]Downloading pytorch_model.bin:  88%|████████▊ | 2.77G/3.13G [00:08<00:01, 315MB/s]Downloading pytorch_model.bin:  90%|████████▉ | 2.81G/3.13G [00:08<00:01, 318MB/s]Downloading pytorch_model.bin:  91%|█████████ | 2.85G/3.13G [00:08<00:00, 320MB/s]Downloading pytorch_model.bin:  92%|█████████▏| 2.89G/3.13G [00:09<00:00, 315MB/s]Downloading pytorch_model.bin:  94%|█████████▎| 2.94G/3.13G [00:09<00:00, 317MB/s]Downloading pytorch_model.bin:  95%|█████████▌| 2.98G/3.13G [00:09<00:00, 320MB/s]Downloading pytorch_model.bin:  96%|█████████▋| 3.02G/3.13G [00:09<00:00, 321MB/s]Downloading pytorch_model.bin:  98%|█████████▊| 3.06G/3.13G [00:09<00:00, 321MB/s]Downloading pytorch_model.bin:  99%|█████████▉| 3.10G/3.13G [00:09<00:00, 312MB/s]Downloading pytorch_model.bin: 100%|██████████| 3.13G/3.13G [00:09<00:00, 318MB/s]
Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]Downloading (…)neration_config.json: 100%|██████████| 147/147 [00:00<00:00, 74.5kB/s]
/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
  0%|          | 0/16100 [00:00<?, ?it/s]Traceback (most recent call last):
  File "flan_t5_spider.py", line 234, in <module>
    main()
  File "flan_t5_spider.py", line 160, in main
    trainer.train()
  File "/usr/local/lib/python3.8/dist-packages/transformers/trainer.py", line 1662, in train
    return inner_training_loop(
  File "/usr/local/lib/python3.8/dist-packages/transformers/trainer.py", line 1930, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/usr/local/lib/python3.8/dist-packages/transformers/trainer.py", line 2700, in training_step
    loss = self.compute_loss(model, inputs)
  File "/usr/local/lib/python3.8/dist-packages/transformers/trainer.py", line 2732, in compute_loss
    outputs = model(**inputs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py", line 1679, in forward
    encoder_outputs = self.encoder(
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py", line 1086, in forward
    layer_outputs = layer_module(
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py", line 693, in forward
    self_attention_outputs = self.layer[0](
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py", line 600, in forward
    attention_output = self.SelfAttention(
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py", line 563, in forward
    attn_weights = nn.functional.dropout(
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py", line 1252, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1024.00 MiB (GPU 0; 39.43 GiB total capacity; 37.99 GiB already allocated; 631.81 MiB free; 38.32 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
  0%|          | 0/16100 [00:00<?, ?it/s]